{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rg-OEQOjTQ49",
        "outputId": "31fd2a22-f813-4a34-cd12-ae505f369a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdfplumber in /usr/local/lib/python3.11/dist-packages (0.11.5)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.11/dist-packages (0.3.16)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.11/dist-packages (0.3.32)\n",
            "Requirement already satisfied: langchain_experimental in /usr/local/lib/python3.11/dist-packages (0.3.4)\n",
            "Requirement already satisfied: faiss_cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: pdfminer.six==20231228 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (20231228)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (11.1.0)\n",
            "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.11/dist-packages (from pdfplumber) (4.30.1)\n",
            "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (3.4.1)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.11/dist-packages (from pdfminer.six==20231228->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (3.11.11)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain_core) (4.12.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.18.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pdfplumber langchain langchain_community langchain_core langchain_experimental faiss_cpu langchain_experimental"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PDFPlumberLoader\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.chains.llm import LLMChain\n",
        "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
        "from langchain.chains import RetrievalQA"
      ],
      "metadata": {
        "id": "0GKxHxaLTbG-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data Loading and Splitting**"
      ],
      "metadata": {
        "id": "FS2tYFVoaRRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PDFPlumberLoader(\"attention.pdf\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "QfwMiwhAToBZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n",
        "documents = text_splitter.split_documents(docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq4C6x1lUuYe",
        "outputId": "c850f253-a134-4104-c957-64e9a2bad157"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-b819d188c7c3>:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  text_splitter = SemanticChunker(HuggingFaceEmbeddings())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Embedding and Vector Database**"
      ],
      "metadata": {
        "id": "cZrPXfySaUkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = HuggingFaceEmbeddings()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTXwbibwVBlJ",
        "outputId": "32619a61-1879-4ff0-acb1-c7a1c65f9049"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-55e52f88ce51>:1: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
            "  embedder = HuggingFaceEmbeddings()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db = FAISS.from_documents(documents, embedder)\n",
        "retriever = db.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\":3})"
      ],
      "metadata": {
        "id": "n3ydlBwfVKgP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yXPVqKQBWZ-x",
        "outputId": "fa7a0d0d-f038-4d40-cb3c-25c52a0aa7e9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_groq\n",
            "  Downloading langchain_groq-0.2.4-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting groq<1,>=0.4.1 (from langchain_groq)\n",
            "  Downloading groq-0.18.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.33 (from langchain_groq)\n",
            "  Downloading langchain_core-0.3.33-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (2.10.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (1.33)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (0.3.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.33->langchain_groq) (9.0.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.33->langchain_groq) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (3.10.15)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.33->langchain_groq) (2.3.0)\n",
            "Downloading langchain_groq-0.2.4-py3-none-any.whl (14 kB)\n",
            "Downloading groq-0.18.0-py3-none-any.whl (121 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.9/121.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.33-py3-none-any.whl (412 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-core, langchain_groq\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.32\n",
            "    Uninstalling langchain-core-0.3.32:\n",
            "      Successfully uninstalled langchain-core-0.3.32\n",
            "Successfully installed groq-0.18.0 langchain-core-0.3.33 langchain_groq-0.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "OZ8kQYM4ZrM_"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "\n",
        "llm = ChatGroq(\n",
        "    groq_api_key=userdata.get('groq'),\n",
        "    temperature = 0,\n",
        "    model_name = \"deepseek-r1-distill-llama-70b\"\n",
        ")"
      ],
      "metadata": {
        "id": "SLVGiNngXwEA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm.invoke(\"What is AI Agents\").content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNN12g5uZQXz",
        "outputId": "d8618ce8-3788-43f4-9e55-5ed3dfb6bff8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "\n",
            "</think>\n",
            "\n",
            "AI agents are software programs that use artificial intelligence to perform tasks that typically require human intelligence. These agents are designed to operate autonomously, making decisions and taking actions based on their programming, the data they are trained on, and the inputs they receive from their environment. AI agents can be simple or complex, depending on their intended application.\n",
            "\n",
            "### Key Characteristics of AI Agents:\n",
            "1. **Autonomy**: They operate independently without constant human intervention.\n",
            "2. **Reactivity**: They respond to changes in their environment or inputs.\n",
            "3. **Proactivity**: They take initiative to achieve specific goals.\n",
            "4. **Social Ability**: They can interact with other agents or humans to accomplish tasks.\n",
            "5. **Learning**: Some agents can improve their performance over time through machine learning.\n",
            "\n",
            "### Types of AI Agents:\n",
            "1. **Simple Reflex Agents**: React to the current state of the environment without considering past events or future goals. Example: A chatbot that responds to frequently asked questions.\n",
            "2. **Model-Based Reflex Agents**: Maintain an internal model of the environment and use it to make decisions. Example: A smart thermostat that adjusts temperature based on usage patterns.\n",
            "3. **Goal-Based Agents**: Designed to achieve specific goals, using strategies and planning. Example: A personal assistant that manages your schedule.\n",
            "4. **Utility-Based Agents**: Make decisions by maximizing a utility function that quantifies the desirability of outcomes. Example: A recommendation system that suggests products based on user preferences.\n",
            "5. **Learning Agents**: Improve their performance over time through machine learning. Example: A self-driving car that adapts to new driving conditions.\n",
            "\n",
            "### Applications of AI Agents:\n",
            "- **Virtual Assistants**: Siri, Alexa, Google Assistant.\n",
            "- **Autonomous Vehicles**: Self-driving cars and drones.\n",
            "- **Robotics**: Industrial robots, service robots, and social robots.\n",
            "- **Recommendation Systems**: Netflix, Amazon, Spotify.\n",
            "- **Smart Home Devices**: Thermostats, security systems, and lighting controls.\n",
            "- **Healthcare**: Diagnostic tools, personalized treatment plans, and patient monitoring.\n",
            "- **Finance**: Algorithmic trading, fraud detection, and financial advisors.\n",
            "\n",
            "### Benefits of AI Agents:\n",
            "- **Efficiency**: Automate repetitive tasks and improve productivity.\n",
            "- **Scalability**: Handle large volumes of data and tasks without human intervention.\n",
            "- **Personalization**: Tailor experiences based on individual preferences and behavior.\n",
            "- **Cost-Effectiveness**: Reduce operational costs by minimizing human labor.\n",
            "\n",
            "### Challenges and Considerations:\n",
            "- **Ethics and Privacy**: Concerns about data privacy, bias, and ethical decision-making.\n",
            "- **Security**: Vulnerability to cyber attacks and misuse.\n",
            "- **Complexity**: Developing sophisticated agents requires advanced AI and machine learning techniques.\n",
            "- **Human-AI Collaboration**: Ensuring effective interaction and trust between humans and AI agents.\n",
            "\n",
            "AI agents are rapidly transforming industries and daily life, offering innovative solutions to complex problems. As technology advances, the capabilities and applications of AI agents will continue to expand.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Prompt**"
      ],
      "metadata": {
        "id": "vZp1-DzxaZsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "1. Use the following piece of context to answer the question at the end.\n",
        "2. If you don't know the answer, just say that \"I dont know\" but don't make answer on your own.\\n\n",
        "3. Keep the answer crisp and limited to 3, 4 sentences\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "Helpful Answer: \"\"\"\n",
        "\n",
        "QA_CHAIN_PROMPT= PromptTemplate.from_template(prompt)"
      ],
      "metadata": {
        "id": "cBwPakW4ZwDF"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(\n",
        "    llm = llm,\n",
        "    prompt = QA_CHAIN_PROMPT,\n",
        "    callbacks = None,\n",
        "    verbose = True\n",
        ")"
      ],
      "metadata": {
        "id": "BxeJcq3Hapbq"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "document_prompt = PromptTemplate(\n",
        "    input_variables=[\"page_content\", \"source\"],\n",
        "    template = \"Context: \\ncontent: {page_content}\\nsource: {source}\"\n",
        ")"
      ],
      "metadata": {
        "id": "FFiXe7dPbtO-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_documents_chain = StuffDocumentsChain(\n",
        "    llm_chain = llm_chain,\n",
        "    document_variable_name=\"context\",\n",
        "    document_prompt = document_prompt,\n",
        "    callbacks = None\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ozAW4fNcHzc",
        "outputId": "169dae59-e669-4e96-85f6-273ea893a12f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-142e58bd6917>:1: LangChainDeprecationWarning: This class is deprecated. Use the `create_stuff_documents_chain` constructor instead. See migration guide here: https://python.langchain.com/docs/versions/migrating_chains/stuff_docs_chain/\n",
            "  combine_documents_chain = StuffDocumentsChain(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA(combine_documents_chain = combine_documents_chain,\n",
        "            verbose = True,\n",
        "            retriever = retriever,\n",
        "            return_source_documents = True)"
      ],
      "metadata": {
        "id": "iHQOjDSdcaMO"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"What is Scaled dot product ?\"\n",
        "response = qa(user_input)[\"result\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGiw2Eidcq7W",
        "outputId": "04f4c9bd-50b3-424c-edc2-f80b95341b13"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-37-cd6843eaec4e>:2: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = qa(user_input)[\"result\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "1. Use the following piece of context to answer the question at the end. \n",
            "2. If you don't know the answer, just say that \"I dont know\" but don't make answer on your own.\n",
            "\n",
            "3. Keep the answer crisp and limited to 3, 4 sentences\n",
            "\n",
            "Context: Context: \n",
            "content: ScaledDot-ProductAttention Multi-HeadAttention\n",
            "Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention consists of several\n",
            "attentionlayersrunninginparallel. ofthevalues,wheretheweightassignedtoeachvalueiscomputedbyacompatibilityfunctionofthe\n",
            "querywiththecorrespondingkey. 3.2.1 ScaledDot-ProductAttention\n",
            "Wecallourparticularattention\"ScaledDot-ProductAttention\"(Figure2). Theinputconsistsof\n",
            "queriesandkeysofdimensiond k,a√ndvaluesofdimensiond v. Wecomputethedotproductsofthe\n",
            "querywithallkeys,divideeachby d ,andapplyasoftmaxfunctiontoobtaintheweightsonthe\n",
            "k\n",
            "values. Inpractice,wecomputetheattentionfunctiononasetofqueriessimultaneously,packedtogether\n",
            "intoamatrixQ.\n",
            "source: attention.pdf\n",
            "\n",
            "Context: \n",
            "content: ThekeysandvaluesarealsopackedtogetherintomatricesK andV. Wecompute\n",
            "thematrixofoutputsas:\n",
            "QKT\n",
            "Attention(Q,K,V)=softmax( √ )V (1)\n",
            "d\n",
            "k\n",
            "Thetwomostcommonlyusedattentionfunctionsareadditiveattention[2],anddot-product(multi-\n",
            "plicative)attention. Dot-productattentionisidenticaltoouralgorithm,exceptforthescalingfactor\n",
            "of √1 . Additiveattentioncomputesthecompatibilityfunctionusingafeed-forwardnetworkwith\n",
            "dk\n",
            "asinglehiddenlayer. Whilethetwoaresimilarintheoreticalcomplexity,dot-productattentionis\n",
            "muchfasterandmorespace-efficientinpractice,sinceitcanbeimplementedusinghighlyoptimized\n",
            "matrixmultiplicationcode. Whileforsmallvaluesofd thetwomechanismsperformsimilarly,additiveattentionoutperforms\n",
            "k\n",
            "dotproductattentionwithoutscalingforlargervaluesofd [3]. Wesuspectthatforlargevaluesof\n",
            "k\n",
            "d ,thedotproductsgrowlargeinmagnitude,pushingthesoftmaxfunctionintoregionswhereithas\n",
            "k\n",
            "extremelysmallgradients4. Tocounteractthiseffect,wescalethedotproductsby √1 . dk\n",
            "3.2.2 Multi-HeadAttention\n",
            "Insteadofperformingasingleattentionfunctionwithd -dimensionalkeys,valuesandqueries,\n",
            "model\n",
            "wefounditbeneficialtolinearlyprojectthequeries,keysandvalueshtimeswithdifferent,learned\n",
            "linearprojectionstod ,d andd dimensions,respectively. Oneachoftheseprojectedversionsof\n",
            "k k v\n",
            "queries,keysandvalueswethenperformtheattentionfunctioninparallel,yieldingd -dimensional\n",
            "v\n",
            "4Toillustratewhythedotproductsgetlarge,assumethatthecomponentsofqandkareindependentrandom\n",
            "variableswithmean0andvariance1.Thentheirdotproduct,q·k=(cid:80)dk\n",
            "q k ,hasmean0andvarianced . i=1 i i k\n",
            "4\n",
            "\n",
            "source: attention.pdf\n",
            "\n",
            "Context: \n",
            "content: FFN(x)=max(0,xW +b )W +b (2)\n",
            "1 1 2 2\n",
            "Whilethelineartransformationsarethesameacrossdifferentpositions,theyusedifferentparameters\n",
            "from layer to layer. Another way of describing this is as two convolutions with kernel size 1. The dimensionality of input and output is d = 512, and the inner-layer has dimensionality\n",
            "model\n",
            "d =2048. ff\n",
            "3.4 EmbeddingsandSoftmax\n",
            "Similarlytoothersequencetransductionmodels,weuselearnedembeddingstoconverttheinput\n",
            "tokensandoutputtokenstovectorsofdimensiond . Wealsousetheusuallearnedlineartransfor-\n",
            "model\n",
            "mationandsoftmaxfunctiontoconvertthedecoderoutputtopredictednext-tokenprobabilities. In\n",
            "ourmodel,wesharethesameweightmatrixbetweenthetwoembeddinglayersandthepre-√softmax\n",
            "lineartransformation,similarto[30]. Intheembeddinglayers,wemultiplythoseweightsby d . model\n",
            "5\n",
            "\n",
            "source: attention.pdf\n",
            "Question: What is Scaled dot product ?\n",
            "Helpful Answer: \u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEdg-YPTc6nh",
        "outputId": "f71e36c0-0be8-40d1-c2aa-71f769ea5b59"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<think>\n",
            "Okay, so I need to figure out what \"Scaled dot product\" is based on the provided context. Let me start by reading through the context carefully.\n",
            "\n",
            "First, I see that the context mentions \"ScaledDot-ProductAttention\" and \"Multi-HeadAttention.\" It explains that in the Scaled Dot-Product Attention, the input consists of queries, keys, and values with specific dimensions. The process involves computing dot products of the query with all keys, then dividing each by the square root of the dimension (d_k). After that, a softmax function is applied to get the weights, which are then used to compute the output by multiplying with the values matrix.\n",
            "\n",
            "The context also compares this with additive attention, noting that dot-product attention is faster and more space-efficient because it uses matrix multiplications. However, without scaling, the dot products can become too large, causing issues with the softmax function's gradients. Scaling by the square root of d_k helps mitigate this problem.\n",
            "\n",
            "So, putting it all together, the scaled dot product in attention mechanisms involves normalizing the dot product by the square root of the key dimension to stabilize training and improve performance.\n",
            "</think>\n",
            "\n",
            "The scaled dot product in attention mechanisms normalizes the dot product of queries and keys by dividing them by the square root of their dimension. This scaling helps stabilize training by preventing the dot products from becoming too large, which can cause issues with the softmax function's gradients. It's a key component in the Scaled Dot-Product Attention, enhancing the model's efficiency and performance.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eagmGOQrdENO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}